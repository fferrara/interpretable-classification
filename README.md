This repository tells stories. 
Stories about how different models can achieve high predictive power by capturing completely different patterns in data. 

By interpreting the patterns they learn we are able to choose which model is the right one, without relying exclusively on metrics about predictive power.

# Case studies

- Interpretable Titanic survival: how to be sure a model learned patterns that match reality
- Interpretable income prediction: how to be sure a model hasn't learned discriminatory bias

# How to run the notebooks

1. Install pipenv
1. Create a virtualenv with `pipenv sync`
1. Access the virtualenv with `pipenv shell`
1. Run `jupyter notebook` from inside the virtualenv